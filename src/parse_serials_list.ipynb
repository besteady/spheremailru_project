{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import requests\n",
    "from selenium import webdriver\n",
    "import re\n",
    "import math\n",
    "from bs4 import BeautifulSoup\n",
    "from multiprocessing.dummy import Pool as ThreadPool\n",
    "from time import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "url_template = \"https://myshows.me/search/all/?page={}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pages_count(item):\n",
    "    items_in_table = 30\n",
    "    count = item.text\n",
    "    count = re.sub(re.compile(r'\\s+'), '', count)\n",
    "    return math.ceil(int(count) / items_in_table)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_serials_on_page(page_id):\n",
    "    global url_template\n",
    "    serial_list_url = url_template.format(page_id)\n",
    "    serial_list_html = requests.get(serial_list_url).text.strip()\n",
    "    soup = BeautifulSoup(serial_list_html, 'html.parser')\n",
    "    print(page_id)\n",
    "    serials = {}\n",
    "    table = soup.findAll('table', class_='catalogTable')\n",
    "    items = table[1].findAll('tr')[1:]\n",
    "    for item in items:\n",
    "        serial_info = item.find('td').find('a')\n",
    "        serial_name = serial_info.text.strip()\n",
    "        serial_url = serial_info.attrs['href']\n",
    "        serials[serial_name] = re.findall(r'\\d+', serial_url)[0]\n",
    "    return serials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_url_list():\n",
    "    global url_template\n",
    "    serial_list_url = url_template.format(0)\n",
    "    serial_list_html = requests.get(serial_list_url).text.strip()\n",
    "    soup = BeautifulSoup(serial_list_html, 'html.parser')\n",
    "    pages_count = get_pages_count(soup.find('span', class_='cFirm'))\n",
    "    \n",
    "    url_list = []\n",
    "    t = ThreadPool(8)\n",
    "    result = t.map(get_serials_on_page, range(pages_count))\n",
    "    t.close()\n",
    "    t.join()\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "serial_list = get_url_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "serials = serial_list[0]\n",
    "for serial_dict in serial_list[1:]:\n",
    "    serials.update(serial_dict)\n",
    "\n",
    "data = pd.DataFrame(list(serials.items()), columns=['Name', 'ID'])\n",
    "with open('serials.csv', mode='w', encoding='utf-8') as f_csv:\n",
    "    data.to_csv(f_csv, index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
